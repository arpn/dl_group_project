{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA20001 Deep Learning - Group Project\n",
    "## Text project\n",
    "\n",
    "**Due Thursday, December 13, before 23:59.**\n",
    "\n",
    "The task is to learn to assign the correct labels to news articles.  The corpus contains ~850K articles from Reuters.  The test set is about 10% of the articles. The data is unextracted in XML files.\n",
    "\n",
    "We're only giving you the code for downloading the data, and how to save the final model. The rest you'll have to do yourselves.\n",
    "\n",
    "Some comments and hints particular to the project:\n",
    "\n",
    "- One document may belong to many classes in this problem, i.e., it's a multi-label classification problem. In fact there are documents that don't belong to any class, and you should also be able to handle these correctly. Pay careful attention to how you design the outputs of the network (e.g., what activation to use) and what loss function should be used.\n",
    "- You may use word-embeddings to get better results. For example, you were already using a smaller version of the GloVE  embeddings in exercise 4. Do note that these embeddings take a lot of memory. \n",
    "- In the exercises we used e.g., `torchvision.datasets.MNIST` to handle the loading of the data in suitable batches. Here, you need to handle the dataloading yourself.  The easiest way is probably to create a custom `Dataset`. [See for example here for a tutorial](https://github.com/utkuozbulak/pytorch-custom-dataset-examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.helsinki.fi/u/jgpyykko/reuters.zip to train/reuters.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.datasets.utils import download_url\n",
    "import zipfile\n",
    "\n",
    "train_path = 'train/'\n",
    "\n",
    "dl_file='reuters.zip'\n",
    "dl_url='https://www.cs.helsinki.fi/u/jgpyykko/'\n",
    "zip_path = os.path.join(train_path, dl_file)\n",
    "if not os.path.isfile(zip_path):\n",
    "    download_url(dl_url + dl_file, root=train_path, filename=dl_file, md5=None)\n",
    "\n",
    "with zipfile.ZipFile(zip_path) as zip_f:\n",
    "    zip_f.extractall(train_path)\n",
    "    #os.unlink(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command downloads and extracts the data files into the `train` subdirectory.\n",
    "\n",
    "The files can be found in `train/`, and are named as `19970405.zip`, etc. You will have to manage the content of these zips to get the data. There is a readme which has links to further descriptions on the data.\n",
    "\n",
    "The class labels, or topics, can be found in the readme file called `train/codes.zip`.  The zip contains a file called \"topic_codes.txt\".  This file contains the special codes for the topics (about 130 of them), and the explanation - what each code means.  \n",
    "\n",
    "The XML document files contain the article's headline, the main body text, and the list of topic labels assigned to each article.  You will have to extract the topics of each article from the XML.  For example: \n",
    "&lt;code code=\"C18\"&gt; refers to the topic \"OWNERSHIP CHANGES\" (like a corporate buyout).\n",
    "\n",
    "You should pre-process the XML to extract the words from the article: the &lt;headline&gt; element and the &lt;text&gt;.  You should not need any other parts of the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "This processes the zips in `train/` without additional extractions to disk and produces a pandas dataframe with results. Finally this dataframe is written to disk in a compressed form for subsequent use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data in train/REUTERS_CORPUS_2/\n",
      "...............................................................................................................................\n",
      "Compressing dataframe to train/train.json.xz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tokyo stocks likely to rise after Dow rebound.</td>\n",
       "      <td>Tokyo stocks are likely to rise in Tuesday's s...</td>\n",
       "      <td>[JAP, M11, MCAT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 111 OF APRIL ...</td>\n",
       "      <td>*\\nCommon position (EC) No 11/97 of 20 Decembe...</td>\n",
       "      <td>[EEC, G15, GCAT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 113 OF APRIL ...</td>\n",
       "      <td>*\\nEcu (97/C 113/01)\\nProposal for a Council D...</td>\n",
       "      <td>[EEC, G15, GCAT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 114 OF APRIL ...</td>\n",
       "      <td>*\\n(Note - contents are displayed in reverse o...</td>\n",
       "      <td>[EEC, G15, GCAT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ L 97 OF APRIL 1...</td>\n",
       "      <td>*\\n(Note - contents are displayed in reverse o...</td>\n",
       "      <td>[EEC, G15, GCAT]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0     Tokyo stocks likely to rise after Dow rebound.   \n",
       "1  OFFICIAL JOURNAL CONTENTS - OJ C 111 OF APRIL ...   \n",
       "2  OFFICIAL JOURNAL CONTENTS - OJ C 113 OF APRIL ...   \n",
       "3  OFFICIAL JOURNAL CONTENTS - OJ C 114 OF APRIL ...   \n",
       "4  OFFICIAL JOURNAL CONTENTS - OJ L 97 OF APRIL 1...   \n",
       "\n",
       "                                                text             codes  \n",
       "0  Tokyo stocks are likely to rise in Tuesday's s...  [JAP, M11, MCAT]  \n",
       "1  *\\nCommon position (EC) No 11/97 of 20 Decembe...  [EEC, G15, GCAT]  \n",
       "2  *\\nEcu (97/C 113/01)\\nProposal for a Council D...  [EEC, G15, GCAT]  \n",
       "3  *\\n(Note - contents are displayed in reverse o...  [EEC, G15, GCAT]  \n",
       "4  *\\n(Note - contents are displayed in reverse o...  [EEC, G15, GCAT]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def getHeadline(root):\n",
    "    return root.find('headline').text\n",
    "\n",
    "def getCodes(root):\n",
    "    metaElem = root.find('metadata')\n",
    "    codesElem = metaElem.findall('codes')\n",
    "    codes = []\n",
    "    for c in codesElem:\n",
    "        for code in c:\n",
    "            codes.append(code.attrib['code'])\n",
    "    return codes\n",
    "\n",
    "def getText(root):\n",
    "    ps = root.find('text').findall('p')\n",
    "    text = []\n",
    "    for p in ps:\n",
    "        text.append(p.text)\n",
    "    return '\\n'.join(text)\n",
    "\n",
    "def parseXML(file):\n",
    "    root = ET.parse(file).getroot()\n",
    "    return getHeadline(root), getText(root), getCodes(root)\n",
    "\n",
    "def parseZip(file):\n",
    "    zf = zipfile.ZipFile(file, 'r')\n",
    "    for xml in zf.namelist():\n",
    "        h,t,cs = parseXML(zf.open(xml))\n",
    "        headlines.append(h)\n",
    "        texts.append(t)\n",
    "        codes.append(cs)\n",
    "\n",
    "data_path = 'train/REUTERS_CORPUS_2/'\n",
    "headlines, texts, codes = [], [], []\n",
    "print('Processing data in', data_path)\n",
    "for f in os.listdir(data_path):\n",
    "    if f.startswith(\"1997\") and f.endswith(\".zip\"):\n",
    "        print('.', end='')\n",
    "        parseZip(data_path+f)\n",
    "\n",
    "df = pd.DataFrame({'headline': headlines, 'text': texts, 'codes': codes})\n",
    "print('\\nCompressing dataframe to train/train.json.xz')\n",
    "df.to_json('train/train.json.xz', orient='records', compression='xz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a preprocessed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[JAP, M11, MCAT]</td>\n",
       "      <td>Tokyo stocks likely to rise after Dow rebound.</td>\n",
       "      <td>Tokyo stocks are likely to rise in Tuesday's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[EEC, G15, GCAT]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 111 OF APRIL ...</td>\n",
       "      <td>*\\nCommon position (EC) No 11/97 of 20 Decembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[EEC, G15, GCAT]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 113 OF APRIL ...</td>\n",
       "      <td>*\\nEcu (97/C 113/01)\\nProposal for a Council D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[EEC, G15, GCAT]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ C 114 OF APRIL ...</td>\n",
       "      <td>*\\n(Note - contents are displayed in reverse o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[EEC, G15, GCAT]</td>\n",
       "      <td>OFFICIAL JOURNAL CONTENTS - OJ L 97 OF APRIL 1...</td>\n",
       "      <td>*\\n(Note - contents are displayed in reverse o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              codes                                           headline  \\\n",
       "0  [JAP, M11, MCAT]     Tokyo stocks likely to rise after Dow rebound.   \n",
       "1  [EEC, G15, GCAT]  OFFICIAL JOURNAL CONTENTS - OJ C 111 OF APRIL ...   \n",
       "2  [EEC, G15, GCAT]  OFFICIAL JOURNAL CONTENTS - OJ C 113 OF APRIL ...   \n",
       "3  [EEC, G15, GCAT]  OFFICIAL JOURNAL CONTENTS - OJ C 114 OF APRIL ...   \n",
       "4  [EEC, G15, GCAT]  OFFICIAL JOURNAL CONTENTS - OJ L 97 OF APRIL 1...   \n",
       "\n",
       "                                                text  \n",
       "0  Tokyo stocks are likely to rise in Tuesday's s...  \n",
       "1  *\\nCommon position (EC) No 11/97 of 20 Decembe...  \n",
       "2  *\\nEcu (97/C 113/01)\\nProposal for a Council D...  \n",
       "3  *\\n(Note - contents are displayed in reverse o...  \n",
       "4  *\\n(Note - contents are displayed in reverse o...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('train/train.json.xz', compression='xz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few items with no headline... Replace with \"missing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codes</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54188</th>\n",
       "      <td>[FRA, GFR, JAP, UK]</td>\n",
       "      <td>None</td>\n",
       "      <td>LONDON, Reuter - Following are the buying and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139410</th>\n",
       "      <td>[USA]</td>\n",
       "      <td>None</td>\n",
       "      <td>General Dynamics Corp bid about $1 billion for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191484</th>\n",
       "      <td>[INDIA, E21, E212, ECAT, M11, MCAT]</td>\n",
       "      <td>None</td>\n",
       "      <td>:Delhi shares surge after budget clears parlia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194718</th>\n",
       "      <td>[INDIA, M11, MCAT]</td>\n",
       "      <td>None</td>\n",
       "      <td>INDIA: Delhi shares rise in hectic afternoon t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248396</th>\n",
       "      <td>[EEC, G154, G155]</td>\n",
       "      <td>None</td>\n",
       "      <td>The future cost of state funding of pensions i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274094</th>\n",
       "      <td>[UK, M11, MCAT]</td>\n",
       "      <td>None</td>\n",
       "      <td>Leading British stocks look set to continue th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      codes headline  \\\n",
       "54188                   [FRA, GFR, JAP, UK]     None   \n",
       "139410                                [USA]     None   \n",
       "191484  [INDIA, E21, E212, ECAT, M11, MCAT]     None   \n",
       "194718                   [INDIA, M11, MCAT]     None   \n",
       "248396                    [EEC, G154, G155]     None   \n",
       "274094                      [UK, M11, MCAT]     None   \n",
       "\n",
       "                                                     text  \n",
       "54188   LONDON, Reuter - Following are the buying and ...  \n",
       "139410  General Dynamics Corp bid about $1 billion for...  \n",
       "191484  :Delhi shares surge after budget clears parlia...  \n",
       "194718  INDIA: Delhi shares rise in hectic afternoon t...  \n",
       "248396  The future cost of state funding of pensions i...  \n",
       "274094  Leading British stocks look set to continue th...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['headline'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.headline.fillna(value=\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we dealing with?\n",
    "Lengths of headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    299773.000000\n",
       "mean         44.307286\n",
       "std           6.841473\n",
       "min           2.000000\n",
       "25%          40.000000\n",
       "50%          45.000000\n",
       "75%          50.000000\n",
       "max         146.000000\n",
       "Name: headline, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.headline.apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lengths of text fields. There seems to be a few light year long items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    299773.000000\n",
       "mean       1443.724795\n",
       "std        1301.359047\n",
       "min           0.000000\n",
       "25%         577.000000\n",
       "50%        1080.000000\n",
       "75%        1948.000000\n",
       "max       51474.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many codes items have? Most have a handful but some can have 10x more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    299773.000000\n",
      "mean          5.182378\n",
      "std           2.173796\n",
      "min           1.000000\n",
      "25%           4.000000\n",
      "50%           5.000000\n",
      "75%           6.000000\n",
      "max          45.000000\n",
      "Name: codes, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff669bfcf60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.codes.apply(len).describe())\n",
    "df.codes.apply(len).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different codes are in data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737\n"
     ]
    }
   ],
   "source": [
    "codesList = df.codes.values\n",
    "codes = []\n",
    "for cs in codesList:\n",
    "    codes += cs\n",
    "print(len(set(codes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about in the text files that give labels for these codes? I have gathered these in one file, `all_codes.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1362"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codes = []\n",
    "with open('train/all_codes.txt', 'r') as f:\n",
    "    ac = f.readlines()\n",
    "    for x in ac:\n",
    "        c,l = x.split('\\t',1)\n",
    "        all_codes.append(c.strip())\n",
    "\n",
    "# Check for duplicates\n",
    "print(len(all_codes)==len(list(set(all_codes))))\n",
    "len(all_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that not all codes that appear in `all_codes.txt` appear in the actual training data. What should we do about this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(codes+all_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is bad. There is two codes in data that do not appear in `all_codes.txt`. I'll bypass this for now by considering only the labels that appear in our data. This has to be changed later when we have a real model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codes = list(set(codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Vocabulary to play with\n",
    "char_to_idx = {ch:i for i,ch in enumerate(set(''.join(list(df.headline.values))))}\n",
    "idx_to_char = {i:ch for i,ch in enumerate(set(''.join(list(df.headline.values))))}\n",
    "\n",
    "class ReutersDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # For now, return simply the headline\n",
    "        # and corresponding codes. We have to\n",
    "        # think what we actually want to feed\n",
    "        # into our model.\n",
    "        cs,h,t = df.iloc[index].values\n",
    "        return self.newsToTensor(h,t), self.codesToTensor(cs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(df)\n",
    "\n",
    "    def codesToTensor(self, codes):\n",
    "        indices = [all_codes.index(c) for c in codes]\n",
    "        target = torch.zeros(len(all_codes))\n",
    "        for i in indices:\n",
    "            target[i] = 1\n",
    "        return target\n",
    "    \n",
    "    def newsToTensor(self, headline, text):\n",
    "        # This is a placeholder.\n",
    "        return torch.tensor([self.oneHot(char_to_idx[c]) for c in headline])\n",
    "    \n",
    "    def oneHot(self, idx):\n",
    "        vec = np.zeros(len(char_to_idx))\n",
    "        vec[idx] = 1\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of our training examples are of different lengths, so we must pad examples such that all examples in a batch have the same length. We'll pad to the length of the longest example in a batch. I don't know if `pytorch` can do this automatically, so I'll give a modified `collate_fn` for our data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# This assumes that the tensor is rank one\n",
    "# and that it's shorter than 'length'.\n",
    "def pad_to_length(tensor, length):\n",
    "    return F.pad(tensor, (0, 0, 0,length-tensor.shape[0]), 'constant', 0)\n",
    "\n",
    "def pad_collate(batch):\n",
    "    max_len = max(map(lambda example: len(example[0]), batch))\n",
    "    xs = [tup[0] for tup in batch]\n",
    "    xs = torch.stack(list(map(lambda x: pad_to_length(x,max_len), xs)))\n",
    "    ys = torch.stack([example[1] for example in batch])\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the dataset and get data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ReutersDataset(df.sample(frac=0.8))\n",
    "test_set = ReutersDataset(df.drop(train_set.df.index))\n",
    "\n",
    "batch_size = 8\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, collate_fn=pad_collate, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, collate_fn=pad_collate, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Using GPU!')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('Using CPU')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder model: character level GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "hidden_state_dim = 256\n",
    "output_dim = len(all_codes)\n",
    "vocabulary_dim = len(char_to_idx)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.gru = nn.GRU(vocabulary_dim, hidden_state_dim, num_layers=2, batch_first=True, dropout=0.5)\n",
    "        self.fc1 = nn.Linear(hidden_state_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "    def forward(self, X):\n",
    "        X,h = self.gru(X)\n",
    "        return self.fc2(F.relu(self.fc1(h[-1])))\n",
    "\n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Copy-pasted functions for training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(epoch, train_vector, logs_per_epoch=7):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    train_loss, correct = 0, 0\n",
    "    num_batches = len(train_loader)\n",
    "    start = time.time()\n",
    "    # Loop over each batch from the training set\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        X = X.to(device).float()\n",
    "        y = y.to(device)\n",
    "        # Zero gradient buffers\n",
    "        optimizer.zero_grad() \n",
    "        # Pass data through the network\n",
    "        output = model(X)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, y)\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % (num_batches//logs_per_epoch) == 0 and batch_idx > 0:\n",
    "            now = time.time()\n",
    "            inputs_per_sec = ((batch_idx+1)*batch_size)/(now-start)\n",
    "            eta_min = (epochs*num_batches-(epoch-1)*num_batches-(batch_idx+1))*batch_size/inputs_per_sec/60\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tInputs/s: {:.1f}\\tRemaining: {:.1f} min'.format(\n",
    "                epoch, batch_idx * len(X), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item(), inputs_per_sec, eta_min))\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_vector.append(train_loss)\n",
    "\n",
    "def validate(loss_vector):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    print('\\nValidating...')\n",
    "    for (X, y) in test_loader:\n",
    "        X = X.to(device).float()\n",
    "        y = y.to(device)\n",
    "        output = model(X)\n",
    "        val_loss += criterion(output, y).data.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "    \n",
    "    print('Validation set: Average loss: {:.4f}\\n'.format(val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating...\n",
      "Validation set: Average loss: 0.6940\n",
      "\n",
      "Epoch: 1 [29976/299773 (10%)]\tLoss: 0.023552\tInputs/s: 643.6\tRemaining: 38.0 min\n",
      "Epoch: 1 [59952/299773 (20%)]\tLoss: 0.032634\tInputs/s: 643.5\tRemaining: 37.3 min\n",
      "Epoch: 1 [89928/299773 (30%)]\tLoss: 0.027021\tInputs/s: 643.5\tRemaining: 36.5 min\n",
      "Epoch: 1 [119904/299773 (40%)]\tLoss: 0.028197\tInputs/s: 643.4\tRemaining: 35.7 min\n",
      "Epoch: 1 [149880/299773 (50%)]\tLoss: 0.020694\tInputs/s: 643.2\tRemaining: 35.0 min\n",
      "Epoch: 1 [179856/299773 (60%)]\tLoss: 0.019644\tInputs/s: 643.3\tRemaining: 34.2 min\n",
      "Epoch: 1 [209832/299773 (70%)]\tLoss: 0.023144\tInputs/s: 643.3\tRemaining: 33.4 min\n",
      "Epoch: 1 [239808/299773 (80%)]\tLoss: 0.017635\tInputs/s: 643.2\tRemaining: 32.6 min\n",
      "Epoch: 1 [269784/299773 (90%)]\tLoss: 0.014607\tInputs/s: 643.1\tRemaining: 31.9 min\n",
      "Epoch: 1 [299760/299773 (100%)]\tLoss: 0.021603\tInputs/s: 643.2\tRemaining: 31.1 min\n",
      "\n",
      "Validating...\n",
      "Validation set: Average loss: 0.0159\n",
      "\n",
      "Epoch: 2 [29976/299773 (10%)]\tLoss: 0.011338\tInputs/s: 587.9\tRemaining: 33.1 min\n",
      "Epoch: 2 [59952/299773 (20%)]\tLoss: 0.011318\tInputs/s: 588.5\tRemaining: 32.3 min\n",
      "Epoch: 2 [89928/299773 (30%)]\tLoss: 0.014386\tInputs/s: 589.1\tRemaining: 31.4 min\n",
      "Epoch: 2 [119904/299773 (40%)]\tLoss: 0.018355\tInputs/s: 589.6\tRemaining: 30.5 min\n",
      "Epoch: 2 [149880/299773 (50%)]\tLoss: 0.012923\tInputs/s: 589.7\tRemaining: 29.7 min\n",
      "Epoch: 2 [179856/299773 (60%)]\tLoss: 0.017326\tInputs/s: 589.8\tRemaining: 28.8 min\n",
      "Epoch: 2 [209832/299773 (70%)]\tLoss: 0.009969\tInputs/s: 590.1\tRemaining: 27.9 min\n",
      "Epoch: 2 [239808/299773 (80%)]\tLoss: 0.014016\tInputs/s: 590.2\tRemaining: 27.1 min\n",
      "Epoch: 2 [269784/299773 (90%)]\tLoss: 0.008875\tInputs/s: 590.4\tRemaining: 26.2 min\n",
      "Epoch: 2 [299760/299773 (100%)]\tLoss: 0.015904\tInputs/s: 590.3\tRemaining: 25.4 min\n",
      "\n",
      "Validating...\n",
      "Validation set: Average loss: 0.0139\n",
      "\n",
      "Epoch: 3 [29976/299773 (10%)]\tLoss: 0.009945\tInputs/s: 601.4\tRemaining: 24.1 min\n",
      "Epoch: 3 [59952/299773 (20%)]\tLoss: 0.006770\tInputs/s: 600.4\tRemaining: 23.3 min\n",
      "Epoch: 3 [89928/299773 (30%)]\tLoss: 0.010680\tInputs/s: 600.1\tRemaining: 22.5 min\n",
      "Epoch: 3 [119904/299773 (40%)]\tLoss: 0.016221\tInputs/s: 599.5\tRemaining: 21.7 min\n",
      "Epoch: 3 [149880/299773 (50%)]\tLoss: 0.013329\tInputs/s: 598.6\tRemaining: 20.9 min\n",
      "Epoch: 3 [179856/299773 (60%)]\tLoss: 0.016203\tInputs/s: 597.7\tRemaining: 20.1 min\n",
      "Epoch: 3 [209832/299773 (70%)]\tLoss: 0.023692\tInputs/s: 597.2\tRemaining: 19.2 min\n",
      "Epoch: 3 [239808/299773 (80%)]\tLoss: 0.019347\tInputs/s: 596.9\tRemaining: 18.4 min\n",
      "Epoch: 3 [269784/299773 (90%)]\tLoss: 0.017144\tInputs/s: 597.5\tRemaining: 17.6 min\n",
      "Epoch: 3 [299760/299773 (100%)]\tLoss: 0.011119\tInputs/s: 597.1\tRemaining: 16.7 min\n",
      "\n",
      "Validating...\n",
      "Validation set: Average loss: 0.0133\n",
      "\n",
      "Epoch: 4 [29976/299773 (10%)]\tLoss: 0.008609\tInputs/s: 566.5\tRemaining: 16.8 min\n",
      "Epoch: 4 [59952/299773 (20%)]\tLoss: 0.007314\tInputs/s: 568.4\tRemaining: 15.8 min\n",
      "Epoch: 4 [89928/299773 (30%)]\tLoss: 0.018822\tInputs/s: 568.4\tRemaining: 14.9 min\n",
      "Epoch: 4 [119904/299773 (40%)]\tLoss: 0.007037\tInputs/s: 568.6\tRemaining: 14.1 min\n",
      "Epoch: 4 [149880/299773 (50%)]\tLoss: 0.024804\tInputs/s: 569.5\tRemaining: 13.2 min\n",
      "Epoch: 4 [179856/299773 (60%)]\tLoss: 0.010215\tInputs/s: 568.3\tRemaining: 12.3 min\n",
      "Epoch: 4 [209832/299773 (70%)]\tLoss: 0.011647\tInputs/s: 568.0\tRemaining: 11.4 min\n",
      "Epoch: 4 [239808/299773 (80%)]\tLoss: 0.015487\tInputs/s: 567.9\tRemaining: 10.6 min\n",
      "Epoch: 4 [269784/299773 (90%)]\tLoss: 0.013288\tInputs/s: 568.0\tRemaining: 9.7 min\n",
      "Epoch: 4 [299760/299773 (100%)]\tLoss: 0.010399\tInputs/s: 567.8\tRemaining: 8.8 min\n",
      "\n",
      "Validating...\n",
      "Validation set: Average loss: 0.0127\n",
      "\n",
      "Epoch: 5 [29976/299773 (10%)]\tLoss: 0.015880\tInputs/s: 634.5\tRemaining: 7.1 min\n",
      "Epoch: 5 [59952/299773 (20%)]\tLoss: 0.011412\tInputs/s: 633.2\tRemaining: 6.3 min\n",
      "Epoch: 5 [89928/299773 (30%)]\tLoss: 0.016773\tInputs/s: 631.8\tRemaining: 5.5 min\n",
      "Epoch: 5 [119904/299773 (40%)]\tLoss: 0.010100\tInputs/s: 615.3\tRemaining: 4.9 min\n",
      "Epoch: 5 [149880/299773 (50%)]\tLoss: 0.019013\tInputs/s: 606.0\tRemaining: 4.1 min\n",
      "Epoch: 5 [179856/299773 (60%)]\tLoss: 0.023173\tInputs/s: 600.1\tRemaining: 3.3 min\n",
      "Epoch: 5 [209832/299773 (70%)]\tLoss: 0.010379\tInputs/s: 596.1\tRemaining: 2.5 min\n",
      "Epoch: 5 [239808/299773 (80%)]\tLoss: 0.013272\tInputs/s: 593.1\tRemaining: 1.7 min\n",
      "Epoch: 5 [269784/299773 (90%)]\tLoss: 0.010809\tInputs/s: 590.7\tRemaining: 0.8 min\n",
      "Epoch: 5 [299760/299773 (100%)]\tLoss: 0.012628\tInputs/s: 590.6\tRemaining: 0.0 min\n",
      "\n",
      "Validating...\n",
      "Validation set: Average loss: 0.0124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "parameters = model.parameters()\n",
    "optimizer = optim.Adam(parameters)\n",
    "\n",
    "epochs = 5\n",
    "losst, lossv = [], []\n",
    "validate([])\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, losst, logs_per_epoch = 10)\n",
    "    validate(lossv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to predict something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted (top-3): ['GCAT' 'GSPO' 'USA']\n",
      "Actual (top-3): ['GCAT', 'GSPO', 'USA']\n"
     ]
    }
   ],
   "source": [
    "test_idx = 13\n",
    "example, _ = test_set[test_idx]\n",
    "top_k = torch.topk(model(example.float().unsqueeze(0)), 3)[1][0].numpy()\n",
    "print('Predicted (top-3):', np.sort(np.array(all_codes)[top_k]))\n",
    "print('Actual (top-3):', sorted(test_set.df.iloc[test_idx].codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your model\n",
    "\n",
    "It might be useful to save your model if you want to continue your work later, or use it for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model file should now be visible in the \"Home\" screen of the jupyter notebooks interface.  There you should be able to select it and press \"download\".\n",
    "\n",
    "## Download test set\n",
    "\n",
    "The testset will be made available during the last week before the deadline and can be downloaded in the same way as the training set.\n",
    "\n",
    "## Predict for test set\n",
    "\n",
    "You will be asked to return your predictions a separate test set.  These should be returned as a matrix with one row for each test article.  Each row contains a binary prediction for each label, 1 if it's present in the image, and 0 if not. The order of the labels is the order of the label (topic) codes.\n",
    "\n",
    "An example row could like like this if your system predicts the presense of the second and fourth topic:\n",
    "\n",
    "    0 1 0 1 0 0 0 0 0 0 0 0 0 0 ...\n",
    "    \n",
    "If you have the matrix prepared in `y` you can use the following function to save it to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results.txt', y, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
